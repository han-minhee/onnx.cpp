{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (2, 128, 9216)\n",
      "Output matches expected: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dequantize_4bit(B_quant, scales, zero_points=None, block_size=32):\n",
    "    N, num_blocks, bytes_per_block = B_quant.shape\n",
    "    K = num_blocks * block_size  \n",
    "\n",
    "    if scales.ndim == 1:\n",
    "        scales = scales.reshape(N, num_blocks)\n",
    "\n",
    "    low_4bit = B_quant & 0x0F  \n",
    "    high_4bit = (B_quant >> 4) & 0x0F  \n",
    "    \n",
    "    quant_values = np.stack([low_4bit, high_4bit], axis=-1)  \n",
    "    quant_values = quant_values.reshape(N, num_blocks, bytes_per_block * 2)  \n",
    "\n",
    "    if zero_points is None:\n",
    "        zero_point = 8\n",
    "        B_dequant = (quant_values * scales[:, :, np.newaxis]) - (scales[:, :, np.newaxis] * zero_point)\n",
    "    else:\n",
    "        zero_points = zero_points.astype(np.float32)\n",
    "        B_dequant = (quant_values * scales[:, :, np.newaxis]) - (scales[:, :, np.newaxis] * zero_points)\n",
    "\n",
    "    B_dequant = B_dequant.reshape(N, K)\n",
    "    B_dequant_T = B_dequant.T  \n",
    "    return B_dequant_T\n",
    "\n",
    "def matmul_nbits(A, B_quant, scales, zero_points=None, block_size=32):\n",
    "    B_dequant_T = dequantize_4bit(B_quant, scales, zero_points, block_size)\n",
    "    Y = np.matmul(A, B_dequant_T)  \n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 0\n",
    "X = np.load(\"model.layers.0.input_layernorm.output_0.npy\")  \n",
    "W = np.load(\"model.layers.0.attn.qkv_proj.MatMul.weight_Q4.npy\")  \n",
    "scales = np.load(\"model.layers.0.attn.qkv_proj.MatMul.weight_scales.npy\")  \n",
    "\n",
    "if scales.ndim == 1:\n",
    "    scales = scales.reshape(W.shape[0], W.shape[1])\n",
    "\n",
    "zero_points = None\n",
    "Y = matmul_nbits(X, W, scales, zero_points, block_size=32)\n",
    "print(\"Output shape:\", Y.shape)\n",
    "\n",
    "expected_output = np.load(\"model.layers.0.attn.qkv_proj.MatMul.output_0.npy\")\n",
    "print(\"Output matches expected:\", np.allclose(Y, expected_output, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (2, 128, 32064)\n",
      "Output matches expected: True\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "X = np.load(\"model.layers.32.final_norm_layernorm.output_0.npy\")  # Shape: [2, 128, 3072]\n",
    "W = np.load(\"lm_head.MatMul.weight_Q4.npy\")  # Shape: [32064, 96, 16]\n",
    "scales = np.load(\"lm_head.MatMul.weight_scales.npy\")  # Shape: [32064, 96]\n",
    "\n",
    "if scales.ndim == 1:\n",
    "    scales = scales.reshape(W.shape[0], W.shape[1])\n",
    "\n",
    "zero_points = None\n",
    "Y = matmul_nbits(X, W, scales, zero_points, block_size=32)\n",
    "print(\"Output shape:\", Y.shape)\n",
    "\n",
    "expected_output = np.load(\"logits.npy\")\n",
    "print(\"Output matches expected:\", np.allclose(Y, expected_output, atol=1e-3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
